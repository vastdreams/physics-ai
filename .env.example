# Beyond Frontier Environment Configuration
# Copy this file to .env and fill in your values
#
# Required values are marked [REQUIRED].
# Optional values have sensible defaults shown after the =.

# ─── Flask / API Server ───────────────────────────────────────
# [REQUIRED in production] Secret key for session signing.
# Generate with: python -c "import secrets; print(secrets.token_hex(32))"
FLASK_SECRET_KEY=
SECRET_KEY=

# Port the API server listens on (default: 5002)
PORT=5002

# ─── Authentication ───────────────────────────────────────────
# JWT signing secret (falls back to SECRET_KEY if unset)
JWT_SECRET=

# Default admin account created on first boot
ADMIN_EMAIL=admin@beyondfrontier.local
ADMIN_PASSWORD=

# ─── LLM — Local (LM Studio / llama.cpp) ─────────────────────
LM_STUDIO_URL=http://127.0.0.1:8080
LM_STUDIO_MODEL=DeepSeek-R1-Distill-Qwen-14B
LM_STUDIO_MAX_CONCURRENT=1
LM_STUDIO_MIN_DELAY=0.5
LM_STUDIO_MAX_TOKENS=512

# LLM circuit breaker — after N failures, reject requests for cooldown seconds
LLM_CIRCUIT_BREAKER_THRESHOLD=5
LLM_CIRCUIT_COOLDOWN=60

# ─── LLM — Ollama ────────────────────────────────────────────
OLLAMA_HOST=http://localhost:11434

# ─── LLM — DeepSeek API (cloud fallback) ─────────────────────
# [REQUIRED if using DeepSeek API] Your API key
DEEPSEEK_API_KEY=

# ─── LLM — Generic OpenAI-compatible server (vLLM, etc.) ─────
LLM_SERVER_URL=http://localhost:8000
LLM_API_KEY=
LLM_BACKEND=throttled_openai

# ─── OpenAI (optional, for LLM integration) ──────────────────
OPENAI_API_KEY=

# ─── Evolution Engine ─────────────────────────────────────────
EVOLUTION_ENABLED=true
EVOLUTION_INTERVAL_SECONDS=300
EVOLUTION_AUTO_APPLY=false
EVOLUTION_MIN_CONFIDENCE=0.3
EVOLUTION_STORAGE_PATH=/tmp/beyondfrontier_evolution

# ─── Dashboard ────────────────────────────────────────────────
DASHBOARD_PORT=8052
BACKEND_URL=http://localhost:5002/api/v1/substrate

# ─── Frontend (set in frontend/.env or CI) ────────────────────
# VITE_API_URL=http://localhost:5002
# VITE_WS_URL=http://localhost:5002

# ─── Database (future) ───────────────────────────────────────
# DATABASE_URL=postgresql://user:password@localhost/beyondfrontier

# ─── Redis (caching) ──────────────────────────────────────────
# Set to enable Redis cache for computations; omit for in-memory fallback
REDIS_URL=redis://localhost:6379/0

# ─── Hot Reload ──────────────────────────────────────────────
ENABLE_HOT_RELOAD=true

# ─── CORS ────────────────────────────────────────────────────
# Comma-separated origins allowed for CORS. Leave empty for same-origin only.
# CORS_ORIGINS=http://localhost:5173,http://your-domain.com
CORS_ORIGINS=

# ─── Environment ──────────────────────────────────────────────
# Set to "production" on your server to disable debug mode and unsafe Werkzeug
FLASK_ENV=development
# ENV=production

# ─── Observability ───────────────────────────────────────────
# Protect the /metrics endpoint with a bearer token (optional, recommended in prod)
METRICS_TOKEN=

# ─── Security ───────────────────────────────────────────────
# IP auto-block threshold (suspicious requests within window triggers block)
# SECURITY_SUSPICIOUS_THRESHOLD=50
# SECURITY_SUSPICIOUS_WINDOW=300
# SECURITY_BLOCK_DURATION=1800
# MAX_REQUEST_SIZE_MB=10

# ─── Logging ──────────────────────────────────────────────────
LOG_LEVEL=INFO

# ─── Build / Deploy ──────────────────────────────────────────
# These are set automatically by CI; no need to touch locally.
# APP_VERSION=dev
# BUILD_SHA=local
# COMMIT_SHA=local
